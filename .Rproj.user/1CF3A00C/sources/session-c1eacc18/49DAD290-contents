---
title: "Tree based models"
author: 
  - name: Marco Gaudio
    affiliation: Master di II livello in Artificial Intelligence & Data Science
date: today
format: 
  revealjs: 
    theme: resources/style.scss
    preview-links: auto
    header-logo: resources/logo.png
    fontsize: 28pt
    slide-number: c
    standalone: true
    scrollable: false
    view-distance: 30
    toc: false
    min-scale: 0.21
    max-scale: 1
    incremental: true
    transition: fade
    transition-speed: slow

filters:
  - reveal-header

execute:
 echo: false
 warning: false
 message: false
 fig-width: 8
 fig-height: 5
---
## Intro

<!-- {background="#43464B"} -->

-   Presentazione del dataset
-   Exploratory data analysis
-   CART Model
-   Random Forest model
-   GBM model
-   Model comparison

## Librerie e pacchetti utilizzati

<!-- {background="#43464B"} -->

```{r}
#| eval: true
#| echo: true
library(MLDataR)
library(dplyr)
library(tidyr)
library(tidymodels)
library(data.table)
library(ConfusionTableR)
library(OddsPlotty)
library(randomForest)
library(caret)
library(rpart)
library(rpart.plot)
library(pROC)
library(gbm3)
set.seed(2021)
```

## Exploratory Data analysis {#sec-r_code}

Il dataset (`heartdisease`, proveniente dal pacchetto `MLDataR`) contiene 918 osservazioni di pazienti e 10 variabili:

::: columns
::: {.column width="50%"}
-   `Age`
-   `Sex`
-   `RestingBP`: pressione sanguigna a riposo
-   `Cholesterol`: Colesterolo
-   `FastingBS`: livello di glucosio
:::

::: {.column width="50%"}
-   `RestingECG`: indicatore miocardico
-   `MaxHR`: battito massimo
-   `Angina`
-   `HeartPeakReading`
-   `HeartDisease`
:::
:::

## Exploratory Data analysis (2)

Analizziamo la percentuale ed il numero di pazienti all'interno del dataset che presentano una malattia cardiaca.

```{r}
#| eval: true
#| echo: true
#| results: markup
heartdisease %>%
  count(HeartDisease) %>%
  mutate(percentage = paste0(round(n / sum(n) * 100, 2), "%")) %>% 
  DT::datatable(
    options = list(
          dom = 't'
          )
  )
```

## Exploratory Data analysis (3)

<!-- :::{.columns} -->

<!-- :::: {.column} -->

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 12
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: false
# distribuzione età
ggplot(heartdisease, aes(x = Age)) + 
  geom_histogram(binwidth = 5, fill = "lightblue", color = "black") + 
  theme_minimal() +
  labs(title = "Distribuzione dell'età", x = "Età", y = "Frequenza")
```

<!-- :::: -->

<!-- :::: {.column} -->

## Exploratory Data analysis (4)

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 12
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: false
# distribuzione colesterolo
ggplot(heartdisease, aes(x = Sex)) + 
  geom_histogram(stat = "count", fill = "lightblue", color = "black") + 
  theme_minimal() +
  labs(title = "Distribuzione per genere", x = "Genere", y = "Frequenza")
```

<!-- :::: -->

<!-- ::: -->

## Exploratory Data analysis (5)

Dall'analisi della correlazione tra le diverse variabili del dataset emerge che alcune di esse sono leggermente correlate tra di lore (e.g., `MaxHR` ed `HeartDisease`).

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 12
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: false
# analisi di correlazione
heartdisease %>%
  select_if(is.numeric) %>%
  cor() %>%
  as.data.frame() %>%
  rownames_to_column(var = "Variable1") %>%
  gather(key = "Variable2", value = "Correlation", -Variable1) %>%
  ggplot(aes(x = Variable1, y = Variable2, fill = Correlation)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", high = "red", mid = "white", midpoint = 0, limit = c(-1, 1), space = "Lab", name = "Correlazione") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Matrice di correlazione")
```

## Dataset: train e test

<!-- {background="#43464B"} -->

Con il seguente codice si procede alla lettura del dataset dal pacchetto `MLDataR`, alla conversione di alcuni datatype ed allo split tra `train` e `test` set.

```{r, echo=TRUE, eval=TRUE}
#| eval: true
#| echo: true
#| code-line-numbers: 1-8|10-18
heartdisease <- MLDataR::heartdisease %>% 
  dplyr::mutate(
    HeartDisease = as.factor(HeartDisease),
    Sex = as.factor(Sex),
    RestingECG = as.factor(RestingECG),
    Angina = as.factor(Angina),
    HeartPeakReading = as.factor(HeartPeakReading)
  )

# creo test dataset e train dataset
train_index <- caret::createDataPartition(
  heartdisease$HeartDisease, 
  p = 0.8, 
  list = FALSE, 
  times = 1
  )
train <- heartdisease[train_index, ]
test <- heartdisease[-train_index, ]
```

## CART model

-   **Classification and Regression Tree**, procedura per costruire l’albero decisionale con una successione di scelte ottime locali, in modo rendere la ricerca del best tree computazionalmente fattibile.
-   Costruzione di un albero profondo prima di procedere al *pruning*.
-   Utilizzo del **cost complexity parameter** per ottenere l'albero ottimale (trade-off complessità/profondità)

```{r}
#| eval: true
#| echo: true
fit <- rpart::rpart(HeartDisease ~ ., 
                    method = "class", 
                    data = train, 
                    control = rpart::rpart.control(
                      cp = 0.01 
                    )
)
```

## Tuning complexity parameter

-   Utilizzando il comando `printcp` possiamo ottenere la media e la deviazione standard degli errori nella previsione della cross validation della variabile `fit`.

```{r}
#| eval: true
#| echo: false
#| include: true
#| message: false
#| warning: false
#| output: false

cp_obj <- rpart::printcp(fit)

```

```{r}
#| eval: true
#| echo: false
#| include: true
#| message: false
#| warning: false
cp_obj %>%  
  as.data.frame() %>% 
  mutate_if(is.numeric, ~round(., 4)) %>% 
  DT::datatable(
    options = list(
          dom = 't'
          )
  )

```

## Tuning complexity parameter (2)

La funzione `plotcp` valutata per l'oggetto `fit` ci suggerisce come effettuare il *pruning*. Si seleziona il valore più a sinistra per il quale la media si trova al di sotto della linea orizzontale.

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 4
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: true
rpart::plotcp(fit)
```

## Pruning CART

- **complexity parameter ottimale** (0.012195);

- **minsplit** pari a 100.

```{r}
#| eval: true
#| echo: true
#| include: true
fit_prune <- rpart::rpart(HeartDisease ~ ., 
                          data = train, control = rpart::rpart.control(
  minsplit = 100,
  cp = 0.012195  
  )
)
```

## Pruning CART (2)

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 4
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: false
rpart.plot::rpart.plot(fit_prune,  type = 4, extra = 104, under = TRUE, fallen.leaves = TRUE)
```

## Accuracy del CART

```{r}
#| eval: true
#| echo: true
#| include: true
prediction_test_cart <- predict(fit_prune, newdata = test, type = "class")
confusionMatrix(prediction_test_cart, test$HeartDisease) 

accuracy_test_cart <- mean(test$HeartDisease == prediction_test_cart)


```

- L'accuratezza del modello CART sul test set è `r round(accuracy_test_cart, 4)`.

## Accuracy del CART (2)

```{r}
#| eval: true
#| echo: true
#| include: true
prediction_train_cart <- predict(fit_prune, type = "class")
confusionMatrix(prediction_train_cart, train$HeartDisease)

accuracy_train_cart <- mean(train$HeartDisease == prediction_train_cart)
```

- L'accuratezza del modello CART sul train set è `r round(accuracy_train_cart, 4)`. 

## Variable importance
<!-- - L’importanza predittiva delle variabili viene misurata dalla *variable importance*, che viene misurata tipicamente come il decremento totale della loss fucntion quando una certa variabile è utilizzata per uno split. -->

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 4
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: false
# Variable importance
var_imp <- fit_prune$variable.importance
var_imp <- tibble::tibble(
  Feature = names(var_imp), 
  Importance = var_imp) %>%
  dplyr::arrange(desc(Importance))
  
ggplot(var_imp, aes(x = reorder(Feature, Importance), y = Importance)) +
  geom_bar(stat = "identity", fill = "lightblue") +
  coord_flip() +
  labs(title = "Variable Importance", x = "Features", y = "Importance") +
  theme_minimal()
```

## ROC curve

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 4
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: false

# Additional plots for better understanding
# Plotting ROC Curve for the test set

# Calculate ROC curve for the test set
prob_test <- predict(fit_prune, newdata = test, type = "prob")[,2]
roc_test <- roc(test$HeartDisease, prob_test, levels = rev(levels(test$HeartDisease)))

# Calculate ROC curve for the training set
prob_train <- predict(fit_prune, type = "prob")[,2]
roc_train <- roc(train$HeartDisease, prob_train, levels = rev(levels(train$HeartDisease)))

# Create a data frame for ggplot
roc_data <- data.frame(
  FPR = c(roc_train$specificities, roc_test$specificities),
  TPR = c(roc_train$sensitivities, roc_test$sensitivities),
  Set = c(rep("Training Set", length(roc_train$specificities)), rep("Test Set", length(roc_test$specificities)))
)

# Plot the ROC curve using ggplot
ggplot(roc_data, aes(x = 1 - FPR, y = TPR, color = Set)) +
  geom_line(size = 1) +
  geom_abline(linetype = "dashed", color = "gray") +
  labs(
    title = "ROC Curve for Training and Test Sets",
    x = "False Positive Rate (1 - Specificity)",
    y = "True Positive Rate (Sensitivity)"
  ) +
  theme_minimal() +
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.title = element_blank()
  ) +
  scale_color_manual(values = c("Training Set" = "lightblue", "Test Set" = "darkblue"))

# Calculate AUC for both training and test sets
auc_train <- auc(roc_train)
auc_test <- auc(roc_test)
# auc_train
# auc_test
```


## Random Forest model
- Insieme (ensemble) di alberi decisionali costruiti su sottoinsiemi casuali del dataset originale e delle sue caratteristiche.
- parametri fondamentali: `ntree` (numero di alberi) e `mtry` (sottoinsieme di feature estratte per ogni split).

```{r, message=FALSE, warning=FALSE}
#| eval: true
#| echo: true
#| message: false
#| warning: false
#| include: true
#| output: false
set.seed(2024)
my_mtry <- randomForest::tuneRF(
  x = train %>% 
    dplyr::select(-HeartDisease),
  y = train$HeartDisease,
  ntreeTry = 300,
  stepFactor = 1.5,
  improve = 0.001)
my_mtry
best_mtry <- my_mtry[which.min(my_mtry[,2]),1]

```
- Il numero ottimale di features da considerare ad ogni split e `r best_mtry`.

## Random Forest model (2)

```{r}
#| eval: true
#| echo: true
#| include: true

rf_best_mtry <- randomForest(HeartDisease ~ ., 
                             data = train, 
                             mtry = best_mtry, 
                             ntree = 250,
                             importance = TRUE)
print(rf_best_mtry)

```

## Accuracy Random Forest

```{r}
#| eval: true
#| echo: true
#| include: true

prediction_test_rf <- predict(rf_best_mtry, newdata = test, type = "class")
confusionMatrix(prediction_test_rf, test$HeartDisease)

accuracy_test_rf <- mean(test$HeartDisease == prediction_test_rf)

```

L'accuratezza sul dataset di test utilizzando il modello random forest è di `r accuracy_test_rf`

## Accuracy Random Forest (2)

```{r}
#| eval: true
#| echo: true
#| include: true
prediction_train_rf <- predict(rf_best_mtry, type = "class")
confusionMatrix(prediction_train_rf, train$HeartDisease)

accuracy_train_rf <- mean(train$HeartDisease == prediction_train_rf)
```
L'accuratezza sul dataset di train utilizzando il modello random forest è di `r accuracy_train_rf`

## Variable importance

```{r}
# | fig-align: center
# | fig-width: 6
# | fig-height: 4
# | fig-pos: ht
# | fig-cap: "The Sampling Distribution."
# | fig-cap-location: bottom
# | label: fig-sampling
# | echo: false
randomForest::varImpPlot(rf_best_mtry, type=1, sort=TRUE, pch=20)
```

## GBM model
- Metodo di ensamble che combina molti modelli deboli;
- Costruisce alberi in sequenza, dove ogni albero successivo cerca di correggere gli errori del precedente.

```{r}
#| eval: true
#| echo: true
#| include: true
gbm_model <- gbm3::gbm(HeartDisease ~ ., 
                 data = train, 
                 distribution = "bernoulli",
                 n.trees = 1500, 
                 interaction.depth = 3, 
                 shrinkage = 0.01, 
                 cv.folds = 5
                 )
```

```{r}
#| eval: true
#| echo: true
#| include: true
# Numero ottimale di iterazioni
optimal_iterations <- gbm3::gbm.perf(gbm_model, method = "cv")
```
- Il numero ottimale di iterazioni è  `r optimal_iterations`.

## Accuracy GBM

```{r}
#| eval: true
#| echo: true
#| include: true
prediction_test_gbm <- predict(gbm_model, 
                               test, 
                               n.trees = optimal_iterations, 
                               type = "response")

predicted_classes_gbm <- ifelse(prediction_test_gbm > 0.5, 1, 0)

predicted_classes <- as.factor(predicted_classes_gbm)
actual_classes <- as.factor(test$HeartDisease)

cm_gbm <- confusionMatrix(predicted_classes, actual_classes)
cm_gbm$table
accuracy_test_gbm <- mean(test$HeartDisease == predicted_classes)
```
- L'accuratezza sul dataset di test utilizzando il modello gbm è di `r accuracy_test_gbm`

## Accuracy GBM (2)

```{r}
#| eval: true
#| echo: true
#| include: true
prediction_train_gbm <- predict(gbm_model, 
                                train, 
                                n.trees = optimal_iterations, 
                                type = "response")

predicted_classes_gbm <- ifelse(prediction_train_gbm > 0.5, 1, 0)

predicted_classes <- as.factor(predicted_classes_gbm)
actual_classes <- as.factor(train$HeartDisease)

cm_gbm_train <- confusionMatrix(predicted_classes, actual_classes)
cm_gbm_train$table

accuracy_train_gbm <- mean(train$HeartDisease == predicted_classes)
```
- L'accuratezza sul dataset di train utilizzando il modello gbm è di `r accuracy_train_gbm`

## Model Comparison

- Il modello con le migliori performance è il GBM.
- Il random forest model sembrerebbe performare peggio del CART model.
- In generale, tutti i modelli potrebbero essere raffinati, ma rimangono comunque risultati accettabili viste le poche osservazioni a disposizione.

```{r}
tibble(
  model = c("CART", "Random Forest", "GBM"),
  accuracy_test = c(accuracy_test_cart, accuracy_test_rf, accuracy_test_gbm),
  accuracy_train = c(accuracy_train_cart, accuracy_train_rf, accuracy_train_gbm)
) %>% 
  dplyr::mutate_if(is.numeric, ~round(., 4)) %>% 
  DT::datatable(
    options = list(
          dom = 't'
          )
  )

```

# Grazie per l'attenzione!

